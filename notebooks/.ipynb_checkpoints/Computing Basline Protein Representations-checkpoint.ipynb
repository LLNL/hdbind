{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import h5py \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "from deepchem.feat import Featurizer\n",
    "from deepchem.utils.coordinate_box_utils import CoordinateBox\n",
    "from deepchem.utils.rdkit_utils import load_molecule\n",
    "from pathlib import Path\n",
    "from deepchem.feat import RdkitGridFeaturizer, BindingPocketFeaturizer\n",
    "from deepchem.utils.coordinate_box_utils import CoordinateBox\n",
    "from deepchem.utils.rdkit_utils import load_molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the pdbbind 2019 paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbbind_2019_path = Path(\"/p/lustre2/jones289/data/raw_data/v2019\")\n",
    "pdbbind_2019_subdirs = pdbbind_2019_path.glob(\"**/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instantiate the deepchem featurizers\n",
    "* RdkitGridFeaturizer\n",
    "* BindingPocketFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdkit_grid_feat = RdkitGridFeaturizer(feature_types=['ecfp', \n",
    "#                                                      'splif', # 'Atom' object has no attribute 'GetIndex'\n",
    "#                                                      'sybyl', # not implemented\n",
    "#                                                      'salt_bridge', # including this feature results in extremely large values (np.inf)\n",
    "                                                     'charge', \n",
    "#                                                      'hbond', # this causes an index error\n",
    "                                                     'pi_stack', # this feature may be equal to 0 much of the time\n",
    "                                                     'cation_pi', # this feature may be equal to 0 much of the time\n",
    "                                                    ],\n",
    "                                      voxel_width=.5, sanitize=True)\n",
    "rdkit_grid_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_pocket_feat = BindingPocketFeaturizer()\n",
    "binding_pocket_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxes_to_atoms(coords: np.ndarray, boxes: List[CoordinateBox]\n",
    "                  ) -> Dict[CoordinateBox, List[int]]:\n",
    "    \"\"\"Maps each box to a list of atoms in that box.\n",
    "      Given the coordinates of a macromolecule, and a collection of boxes,\n",
    "      returns a dictionary which maps boxes to the atom indices of the\n",
    "      atoms in them.\n",
    "      Parameters\n",
    "      ----------\n",
    "      coords: np.ndarray\n",
    "        A numpy array of shape `(N, 3)`\n",
    "      boxes: list\n",
    "        List of `CoordinateBox` objects.\n",
    "      Returns\n",
    "      -------\n",
    "      Dict[CoordinateBox, List[int]]\n",
    "        A dictionary mapping `CoordinateBox` objects to lists of atom indices.\n",
    "      \"\"\"\n",
    "\n",
    "    mapping = {}\n",
    "    for box_ind, box in enumerate(boxes):\n",
    "        box_atoms = []\n",
    "        for atom_ind in range(len(coords)):\n",
    "            atom = coords[atom_ind]\n",
    "            if atom in box:\n",
    "                box_atoms.append(atom_ind)\n",
    "        mapping[box] = box_atoms\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_box(xyz):\n",
    "    \n",
    "    xyz = xyz.squeeze()\n",
    "    x_min, x_max, y_min, y_max, z_min, z_max = xyz[:, 0].min(), \\\n",
    "                    xyz[:, 0].max(), xyz[:, 1].min(), xyz[:, 1].max(), \\\n",
    "                    xyz[:, 2].min(), xyz[:, 2].max()\n",
    "    \n",
    "    crystal_box = CoordinateBox(x_range=(x_min-1, x_max+1), \\\n",
    "                                y_range=(y_min-1, y_max+1), \\\n",
    "                                z_range=(z_min-1, z_max+1))\n",
    "\n",
    "    return crystal_box\n",
    "\n",
    "    \n",
    "def featurize_complex_job(parent_dir, use_prot=False, use_pocket=True, verbose=False):\n",
    "    \n",
    "    assert use_prot != use_pocket\n",
    "    \n",
    "    pdbid = parent_dir.stem\n",
    "    \n",
    "    if use_prot:\n",
    "        mol_path = parent_dir.with_name(pdbid) / f\"{pdbid}_protein.pdb\"\n",
    "    if use_pocket:\n",
    "        # the RDKitGridFeaturizer is choking on these file...and the error is being thrown by mdtraj..files are coming directly from pdbbind\n",
    "        mol_path = parent_dir.with_name(pdbid) / f\"{pdbid}_pocket.pdb\"\n",
    "        \n",
    "    lig_path = parent_dir.with_name(\"ligands\") / f\"{pdbid}_ligand.pdb\"\n",
    "    \n",
    "#     print(mol_path)\n",
    "     \n",
    "#     '''\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        if use_pocket:\n",
    "            pocket_coords, pocket_mol = load_molecule(str(mol_path), add_hydrogens=False, calc_charges=False)\n",
    "            crystal_box = compute_box(pocket_coords)\n",
    "        \n",
    "            try:\n",
    "                rdkit_feats = rdkit_grid_feat._featurize((str(mol_path), str(lig_path)))\n",
    "                bind_pocket_feats = binding_pocket_feat.featurize(str(mol_path), pockets=[crystal_box])\n",
    "                #             feats = bind_pocket_feats\n",
    "                feats = np.asarray([rdkit_feats, bind_pocket_feats])\n",
    "                return pdbid, feats\n",
    "\n",
    "            except (AttributeError, OSError, Exception) as e:\n",
    "                print(pdbid, e)\n",
    "#     '''\n",
    "\n",
    "def process_data(pdbbind_2019_subdir_list):\n",
    "    \n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        result_list = list(tqdm(pool.imap(featurize_complex_job, pdbbind_2019_subdir_list), \n",
    "                                total=len(pdbbind_2019_subdir_list)))\n",
    "    \n",
    "    return result_list\n",
    "    \n",
    "def dump_result_to_h5(result_list, output_path):\n",
    "    assert output_path is not None\n",
    "    with h5py.File(output_path, 'w') as f:\n",
    "        for result in tqdm(result_list, desc=\"dumping output to hdf5 file...\"):\n",
    "            pdbid = result[0]\n",
    "            binding_pocket_feat = result[1]\n",
    "            \n",
    "            print(binding_pocket_feat.shape)\n",
    "#             print(pdbid)\n",
    "#             '''\n",
    "            affinity = pdbbind_2019_df.loc[pdbbind_2019_df['pdbid'] == pdbid]['-logKd/Ki']\n",
    "            pdbid_group = f.require_group(pdbid)\n",
    "            pdbid_group.attrs['-logKd/Ki'] = affinity\n",
    "            pdbid_group.require_dataset(\"BindingPocketFeaturizer\",\n",
    "                                        data=result[1], \n",
    "                                        shape=result[1].shape, \n",
    "                                        dtype=np.float32)\n",
    "#             '''\n",
    "    \n",
    "    print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbbind_2019_df = pd.read_csv(\"/p/lustre2/jones289/data/pdbbind/metadata/pdbbind_v2019_metadata.csv\")\n",
    "print(pdbbind_2019_df.head())\n",
    "pdbbind_2019_path = Path(\"/p/lustre2/jones289/data/raw_data/v2019\")\n",
    "pdbbind_2019_subdirs = pdbbind_2019_path.glob(\"*/\")\n",
    "pdbbind_2019_subdir_list = list(pdbbind_2019_subdirs)\n",
    "pdbbind_2019_subdir_list = [x for x in pdbbind_2019_subdir_list if x.name in pdbbind_2019_df['name'].values.tolist()]\n",
    "print(len(pdbbind_2019_subdir_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = process_data(pdbbind_2019_subdir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_result_to_h5(result_list, \"deepchem_baseline_feats.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"deepchem_baseline_feats.h5\", 'r') as f:\n",
    "    print(list(f['1a30']['BindingPocketFeaturizer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_df = pd.read_csv('/g/g13/jones289/workspace/hd-cuda-master/datasets/pdbbind_fingerprints/' \\\n",
    "                         + 'pdbbind_2016_fps_new/v_2016_refined_pdbid_list.csv', index_col=0)\n",
    "refined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_label_dist(df, bind_thresh=4):\n",
    "    non_bind_df = df\n",
    "    f, ax = plt.subplots(1,1)\n",
    "    non_bind_df['label'] = refined_df.apply(\n",
    "                lambda x: int(x['-logKd/Ki'] > bind_thresh), axis=1)\n",
    "    ax.set_title(f\"no-bind (0) and bind (1) counts with thresh={bind_thresh}\")\n",
    "    sns.countplot(non_bind_df['label'], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(refined_df['-logKd/Ki'])\n",
    "\n",
    "for thresh in [2,4,6,8, 10]:\n",
    "    visualize_label_dist(refined_df, bind_thresh=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = [x for x in data.keys()]\n",
    "id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values = np.asarray([x for x in data.values()]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_set_df = pd.read_csv(\"/p/lustre2/jones289/data\" \\\n",
    "                          + \"/pdbbind/metadata/\" \\\n",
    "                          + \"pdbbind_2016_core_test.csv\")\n",
    "core_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_test_dict = {key: {'data': value, \n",
    "                        '-logKd/Ki': core_set_df[core_set_df['pdbid'] == key]['-logKd/Ki'].values} \n",
    "                  for key,value in data.items() if key in core_set_df['pdbid'].values}\n",
    "core_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(core_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbbind_2016_df = pd.read_csv('/p/lustre2/jones289/data/pdbbind/metadata/pdbbind_2016_train_val_test.csv')\n",
    "refined_set_df = pdbbind_2016_df[pdbbind_2016_df.apply(lambda x: x['pdbbind_set'] == 'refined', axis=1)]\n",
    "refined_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_no_core_set_df = refined_set_df[refined_set_df['pdbid'].apply(lambda x: x not in core_test_dict.keys())]\n",
    "refined_no_core_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_train_dict = {key:value for key,value in data.items() if key in refined_no_core_set_df['pdbid'].values}\n",
    "refined_train_dict\n",
    "\n",
    "refined_train_dict = {key: {'data': value, \n",
    "                        '-logKd/Ki': refined_no_core_set_df[refined_no_core_set_df['pdbid'] == key]['-logKd/Ki'].values} \n",
    "                  for key,value in data.items() if key in refined_no_core_set_df['pdbid'].values}\n",
    "len(refined_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_tup(mydict, binary_only=False, upper_thresh=8, lower_thresh=6):\n",
    "    \n",
    "    pdbids = list(mydict.keys())\n",
    "    data = [value['data'].flatten() for key,value in mydict.items()]\n",
    "    labels = [value['-logKd/Ki'] for key,value in mydict.items()]\n",
    "    \n",
    "    class_labels = []\n",
    "    for label in labels:\n",
    "        if label > upper_thresh:\n",
    "            class_labels.append(1)\n",
    "        elif label < lower_thresh:\n",
    "            class_labels.append(0)\n",
    "        else:\n",
    "            class_labels.append(2)\n",
    "    if not binary_only:\n",
    "            \n",
    "        return pdbids, data, class_labels\n",
    "    else:\n",
    "        \n",
    "        binary_pdbids =[]\n",
    "        binary_data = []\n",
    "        binary_labels = []\n",
    "        \n",
    "        for pdbid, el, class_label in zip(pdbids, data, class_labels):\n",
    "            if class_label == 2:\n",
    "                pass\n",
    "            else:\n",
    "#                 print(pdbid, class_label)\n",
    "                binary_pdbids.append(pdbid)\n",
    "                binary_data.append(el)\n",
    "                binary_labels.append(class_label)\n",
    "        \n",
    "#         print(type(binary_labels), np.unique(binary_labels))\n",
    "        return binary_pdbids, binary_data, binary_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dataset(core_data_dict, refined_data_dict):\n",
    "    \n",
    "    for upper, lower in ([(6,8), (4,4), (6,6)]):\n",
    "        core_ids, core_data, core_labels = convert_dict_to_tup(core_data_dict, binary_only=True,\n",
    "                                                      upper_thresh=upper, lower_thresh=lower)\n",
    "        with open(f'deepchem_aa_prot_feats_core_2_class_{lower}_{upper}_thresh.pkl', 'wb') as handle:\n",
    "            pickle.dump((core_data, core_labels), handle)\n",
    "        \n",
    "        \n",
    "        refined_ids, refined_data, refined_labels = convert_dict_to_tup(refined_train_dict, binary_only=True,\n",
    "                                                               upper_thresh=upper, lower_thresh=lower)\n",
    "    \n",
    "        with open(f'deepchem_aa_prot_feats_refined_2_class_{lower}_{upper}_thresh.pkl', 'wb') as handle:\n",
    "            pickle.dump((refined_data, refined_labels), handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dataset(core_test_dict, refined_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_feats(feats):\n",
    "    voxels, aa_count_feat = feats\n",
    "    for dim in range(voxels.shape[-1]):\n",
    "        min_vox = voxels[:,:,:,dim].min()\n",
    "        max_vox = voxels[:,:,:,dim].max()\n",
    "        mean_vox = voxels[:,:,:,dim].mean()\n",
    "        \n",
    "        flat_voxels = voxels[:, :,:, dim].flatten()\n",
    "        occ_rate = 100 * (flat_voxels[flat_voxels != 0].shape[0] / flat_voxels.shape[0])\n",
    "        print(f\"i: {dim}, min={min_vox}, max={max_vox}, mean_vox={mean_vox}, occupancy%: {occ_rate:0.4f}\")\n",
    "    \n",
    "#         print(flat_voxels[flat_voxels != 0])\n",
    "#         print(feats[0].shape)\n",
    "#         print(voxels.shape)\n",
    "    print(aa_count_feat)\n",
    "    print(aa_count_feat.sum(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_feats(feats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomsci-intel-pascal",
   "language": "python",
   "name": "atomsci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
