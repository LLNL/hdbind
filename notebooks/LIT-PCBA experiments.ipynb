{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIT-PCBA \n",
    "this dataset is a proposed \"more difficult\" test than DUD-E. I used a 75/25 (sklearn default) stratified split. The dataset is heavily imbalanced, like DUD-E."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# sys.path.append('..')\n",
    "sys.path.insert(0, \"/g/g13/jones289/workspace/hd-cuda-master\")\n",
    "# print(sys.path)\n",
    "import hdpy\n",
    "import hdpy.ecfp\n",
    "from hdpy.analysis import load_pkl\n",
    "from hdpy.metrics import compute_enrichment_factor\n",
    "\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick', labelsize=15)\n",
    "plt.rc('ytick', labelsize=15)\n",
    "plt.rc('axes', labelsize=17)\n",
    "plt.rc('figure', titlesize=20)\n",
    "\n",
    "\n",
    "# SEED=125\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p = Path(f\"/g/g13/jones289/workspace/hd-cuda-master/hdpy/hdpy/results/{SEED}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_color_pal = sns.color_palette(\"Greens\", 10)\n",
    "blue_color_pal = sns.color_palette(\"Blues\", 10)\n",
    "rocket_color_pal = sns.color_palette(\"rocket\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "color_dict = {\n",
    "    \"hdbind-rp-molformer\": rocket_color_pal[2]\n",
    "#     \"smiles-pe.atomwise.0\": rocket_color_pal[2],\n",
    "#     \"smiles-pe.bpe.0\": rocket_color_pal[4],   \n",
    "# \"selfies.atomwise\": green_color_pal[4],\n",
    "#     \"ecfp\": green_color_pal[6],\n",
    "#     \"rp\": green_color_pal[8],\n",
    "#     \"rf\": blue_color_pal[4],\n",
    "#     \"mlp\": blue_color_pal[7],\n",
    "#     \"HDC-MLP\": green_color_pal[9],\n",
    "#     \"HDC-RF\": green_color_pal[9],\n",
    "#     \"Vina\": \"salmon\",\n",
    "}\n",
    "\n",
    "\n",
    "model_order_list = [\n",
    "    (\"hdbind-rp-molformer\", \"HDBind+MolFormer\")\n",
    "#     (\"smiles-pe.atomwise.0\", \"MoleHD-Atomw.\"),\n",
    "#     (\"smiles-pe.bpe.0\", \"MoleHD-BPE\"),\n",
    "#     (\"smiles-pe.ngram.1\", \"SMILES uni-gram\"),\n",
    "#     (\"selfies.atomwise\", \"HDBind-SELFIES\"),\n",
    "#     (\"selfies.selfies-charwise\", \"SELFIES uni-gram\"),\n",
    "#     (\"ecfp\", \"HDBind-ECFP\"),\n",
    "#     (\"rp\", \"HDBind-ECFP+RP\"),\n",
    "#     (\"rf\", \"RF\"),\n",
    "#     (\"mlp\", \"MLP\"),\n",
    "#     (\"Vina\", \"Vina\")\n",
    "]\n",
    "\n",
    "\n",
    "model_name_dict = {\n",
    "    \"hdbind-rp-molformer\": \"HDBind+MolFormer\"\n",
    "#     \"smiles-pe.atomwise.0\": \"MoleHD-Atomw.\", \n",
    "#     \"smiles-pe.bpe.0\": \"MoleHD-BPE\",\n",
    "#     \"smiles-pe.ngram.1\": \"SMILES uni-gram\",\n",
    "#     \"selfies.atomwise\": \"HDBind-SELFIES\",\n",
    "#     \"selfies.selfies-charwise\": \"SELFIES uni-gram\",\n",
    "#     \"ecfp\": \"HDBind-ECFP\",\n",
    "#     \"rp\": \"HDBind-RPFP\",\n",
    "#     \"rf\": \"RF\",\n",
    "#     \"mlp\": \"MLP\",\n",
    "#     \"Vina\": \"Vina\",\n",
    "#     \"HDC-MLP\": \"HDC-MLP\",\n",
    "#     \"HDC-RF\": \"HDC-RF\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIT-PCBA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "def compute_metrics(y_pred, y_score, y_true):\n",
    "    \n",
    "    return {\"precision\": precision_score(y_pred=y_pred, y_true=y_true, zero_division=0),\n",
    "            \"recall\": recall_score(y_pred=y_pred, y_true=y_true),\n",
    "           \"f1\": f1_score(y_pred=y_pred, y_true=y_true, zero_division=0),\n",
    "#            \"roc\": roc_auc_score(y_score=y_score, y_true=y_true)\n",
    "           }\n",
    "\n",
    "\n",
    "def aggregate_results(dataset, range_limit=10, multistep_initial_p=None, \n",
    "                      multistep_p_list=None, \n",
    "                      multistep_sklearn_model=None):\n",
    "    \n",
    "\n",
    "    model_metric_dict = {\"model\": [], \"enrich\": [], \"p\":[], \"train_time\":[], \"test_time\": [], \"target\": [],\n",
    "                        \"seed\": [], \"recall\": [], \"precision\": [], \"f1\": [], \n",
    "#                          \"roc\": []\n",
    "                        }\n",
    "    tokenizer=\"atomwise\"\n",
    "    ngram_order=0\n",
    "    for model, color in tqdm(color_dict.items(), total=len(color_dict), position=0):\n",
    "                        \n",
    "        metric_list = []\n",
    "        encode_time_list = []\n",
    "        train_time_list = []\n",
    "        test_time_list = []\n",
    "        train_size_list = []\n",
    "        test_size_list = []\n",
    "        target_size_list = []\n",
    "        eta_list = []\n",
    "\n",
    "        \n",
    "        if model not in [\"HDC-MLP\", \"HDC-RF\"]:\n",
    "            data_path_list = list(data_p.glob(f\"{dataset.replace('-','_')}*.{model}*pkl\"))\n",
    "\n",
    "        elif model in [\"HDC-MLP\", \"HDC-RF\"]:\n",
    "            data_path_list = list(data_p.glob(f\"{dataset.replace('-','_')}*.ecfp*pkl\"))\n",
    "        \n",
    "#     '''\n",
    "\n",
    "        for path in tqdm(data_path_list, total=len(data_path_list), position=1):\n",
    "\n",
    "            \n",
    "            with open(path, \"rb\") as handle:\n",
    "                model_data_dict = pickle.load(handle)\n",
    "\n",
    "            \n",
    "            target = path.name.split(\".\")[1]\n",
    "            \n",
    "            # just choosing this as a debug case\n",
    "#             if target not in [\"GBA\", \"ALDH1\"]:\n",
    "#                 continue\n",
    "            \n",
    "            print(target, path, model)\n",
    "\n",
    "            hd_cache_dir = f\"/p/lustre2/jones289/hd_cache/125/ecfp/{dataset}/random\"\n",
    "\n",
    "            for seed in range(range_limit):\n",
    "                                \n",
    "                    \n",
    "#                 DEBUG_SIZE=100  \n",
    "#                 y_test = model_data_dict[\"y_test\"][:DEBUG_SIZE]\n",
    "#                 x_test = model_data_dict[\"x_test\"][:DEBUG_SIZE]\n",
    "                y_test = model_data_dict[\"y_test\"]\n",
    "                x_test = model_data_dict[\"x_test\"]\n",
    "                actives_database = sum(y_test)\n",
    "                database_size = y_test.shape[0]\n",
    "                \n",
    "                eta = None \n",
    "                \n",
    "\n",
    "                if model in [\"rf\", \"mlp\"]:\n",
    "\n",
    "\n",
    "                    for p in [.01, .1]:\n",
    "\n",
    "                        sklearn_model = model_data_dict[seed][\"model\"]\n",
    "\n",
    "                        y_score = sklearn_model.predict_proba(x_test)[:, 1]            \n",
    "                        y_pred = sklearn_model.predict(x_test)\n",
    "                        enrich = compute_enrichment_factor(sample_scores=y_score, \n",
    "                                                sample_labels=y_test,\n",
    "                                                n_percent=p, \n",
    "                                                actives_database=actives_database, \n",
    "                                                database_size=database_size)\n",
    "\n",
    "                \n",
    "                        metrics = compute_metrics(y_pred=y_pred, y_score=y_score, y_true=y_test)\n",
    "                \n",
    "                        model_metric_dict[\"model\"].append(model)\n",
    "                        model_metric_dict[\"target\"].append(target)\n",
    "                        model_metric_dict[\"enrich\"].append(enrich)\n",
    "                        model_metric_dict[\"p\"].append(p)\n",
    "                        model_metric_dict[\"seed\"].append(seed)\n",
    "                        model_metric_dict[\"precision\"].append(metrics[\"precision\"])\n",
    "                        model_metric_dict[\"recall\"].append(metrics[\"recall\"])\n",
    "                        model_metric_dict[\"f1\"].append(metrics[\"f1\"])\n",
    "#                         model_metric_dict[\"roc\"].append(metrics[\"roc\"])\n",
    "\n",
    "                        \n",
    "                elif model.lower() in [\"hdc-rf\", \"hdc-mlp\"]:\n",
    "\n",
    "                    sklearn_result_file = Path(f\"{data_p}/{dataset.replace('-', '_')}.{target}.{multistep_sklearn_model}.None.{ngram_order}.pkl\")\n",
    "\n",
    "                    with open(sklearn_result_file, \"rb\") as handle:\n",
    "                        sklearn_result_dict = pickle.load(handle)\n",
    "\n",
    "                    target_test_hv_path = f\"{hd_cache_dir}/{target}/test_dataset_hv.pth\"\n",
    "\n",
    "                    hv_test = torch.load(target_test_hv_path, map_location=\"cpu\")\n",
    "                    hdc_conf_scores = model_data_dict[seed][\"model\"].compute_confidence(hv_test)\n",
    "\n",
    "#                     # filter the data\n",
    "                    idxs = np.flip(np.argsort(hdc_conf_scores.squeeze().cpu().numpy(), kind=\"stable\"))\n",
    "\n",
    "                    \n",
    "                    sample_n = int(multistep_initial_p * y_test.shape[0])\n",
    "                    samp_idxs = idxs[:sample_n]\n",
    "                    \n",
    "\n",
    "                    x_test_samp = x_test[samp_idxs]\n",
    "                    y_test_samp = y_test[samp_idxs]\n",
    "                                            \n",
    "    \n",
    "                    for p in multistep_p_list:\n",
    "\n",
    "                        sklearn_model = sklearn_result_dict[seed][\"model\"]\n",
    "            \n",
    "                        sklearn_scores_samp = sklearn_model.predict_proba(x_test_samp)[:, 1]                        \n",
    "            \n",
    "                        y_pred = sklearn_model.predict(x_test_samp)\n",
    "                        enrich = compute_enrichment_factor(sample_scores=sklearn_scores_samp, \n",
    "                                                sample_labels=y_test_samp,\n",
    "                                                n_percent=p, \n",
    "                                                actives_database=actives_database, \n",
    "                                                database_size=database_size)\n",
    "\n",
    "\n",
    "                        metrics = compute_metrics(y_pred=y_pred, y_score=sklearn_scores_samp, y_true=y_test_samp)\n",
    "                \n",
    "                        model_metric_dict[\"model\"].append(model)\n",
    "                        model_metric_dict[\"target\"].append(target)\n",
    "                        model_metric_dict[\"enrich\"].append(enrich)\n",
    "                        model_metric_dict[\"p\"].append(round(multistep_initial_p * p, 2))\n",
    "                        model_metric_dict[\"seed\"].append(seed)\n",
    "                        model_metric_dict[\"precision\"].append(metrics[\"precision\"])\n",
    "                        model_metric_dict[\"recall\"].append(metrics[\"recall\"])\n",
    "                        model_metric_dict[\"f1\"].append(metrics[\"f1\"])\n",
    "#                         model_metric_dict[\"roc\"].append(metrics[\"roc\"])\n",
    "                    \n",
    "\n",
    "                else:                  \n",
    "                    \n",
    "                    target_test_hv_path = f\"{hd_cache_dir}/{target}/test_dataset_hv.pth\"\n",
    "                \n",
    "                    hv_test = torch.load(target_test_hv_path, map_location=\"cpu\")\n",
    "                    hdc_conf_scores = model_data_dict[seed][\"model\"].compute_confidence(hv_test)\n",
    "                    \n",
    "                    for p in [.01, .1]:\n",
    "\n",
    "                        enrich = compute_enrichment_factor(sample_scores=hdc_conf_scores, \n",
    "                                                sample_labels=y_test,\n",
    "                                                n_percent=p, \n",
    "                                                actives_database=actives_database, \n",
    "                                                database_size=database_size)\n",
    "                        y_pred = model_data_dict[seed][\"y_pred\"]\n",
    "                        metrics = compute_metrics(y_pred=y_pred, y_score=hdc_conf_scores, y_true=y_test)\n",
    "                \n",
    "                        model_metric_dict[\"model\"].append(model)\n",
    "                        model_metric_dict[\"target\"].append(target)\n",
    "                        model_metric_dict[\"enrich\"].append(enrich)\n",
    "                        model_metric_dict[\"p\"].append(p)\n",
    "                        model_metric_dict[\"seed\"].append(seed)\n",
    "                        model_metric_dict[\"precision\"].append(metrics[\"precision\"])\n",
    "                        model_metric_dict[\"recall\"].append(metrics[\"recall\"])\n",
    "                        model_metric_dict[\"f1\"].append(metrics[\"f1\"])\n",
    "#                         model_metric_dict[\"roc\"].append(metrics[\"roc\"])\n",
    "\n",
    "                #TODO: implement this \n",
    "#                 model_metric_dict[\"train_time\"].append(train_time)\n",
    "#                 model_metric_dict[\"test_time\"].append(test_time)\n",
    "\n",
    "    return model_metric_dict\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VINA result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def docking_main(nrows=None):\n",
    "    root_p = Path(\"/p/lustre2/ahashare/zhang30/LIT-PCBA-Data/\")\n",
    "\n",
    "    path_list = [path for path in root_p.glob(\"*-actives.csv\")]\n",
    "\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for idx, path in tqdm(enumerate(path_list), total=len(path_list)):\n",
    "        print(idx, path)\n",
    "        \n",
    "#         '''\n",
    "        target = path.name.split(\".\")[0].split(\"-\")[0]\n",
    "        print(target, idx+1, path)\n",
    "        \n",
    "        \n",
    "\n",
    "        merged_df = None\n",
    "        merged_df_path = Path(f\"./lit_pcba_docking_analysis/{target}.csv\")\n",
    "        \n",
    "        if not merged_df_path.exists():\n",
    "            # can use the set of smiles in each result file\n",
    "            result_pkl = Path(f\"/g/g13/jones289/workspace/hd-cuda-master/hdpy/hdpy/results/124/lit_pcba.{target}.ecfp.atomwise.0.pkl\")        \n",
    "\n",
    "\n",
    "            target_train_smiles_list = []\n",
    "            target_test_smiles_list = []\n",
    "\n",
    "            with open(result_pkl, \"rb\") as handle:\n",
    "\n",
    "                data = pickle.load(handle)\n",
    "\n",
    "                target_train_smiles_list = data[\"smiles_train\"]\n",
    "                target_test_smiles_list = data[\"smiles_test\"]\n",
    "\n",
    "                print(f\"total of {len(target_train_smiles_list)} in training set, total of {len(target_test_smiles_list)} in testing set.\")\n",
    "\n",
    "            df_cols = ['file', ' scores/1', ' ligName']\n",
    "            active_df = pd.read_csv(root_p / Path(f\"{target}-actives.csv.clean\"), sep=\",\", usecols=df_cols, nrows=nrows)\n",
    "            active_df['y_true'] = [1] * len(active_df)\n",
    "\n",
    "\n",
    "\n",
    "            inactive_df = pd.read_csv(root_p / Path(f\"{target}-inactives.csv.clean\"), sep=\",\", usecols=df_cols, nrows=nrows)\n",
    "            inactive_df['y_true'] = [0] * len(inactive_df)\n",
    "\n",
    "            target_df = pd.concat([active_df, inactive_df])\n",
    "            # this will search over all of the docking results for each target, across each of the multiple protein models\n",
    "\n",
    "            active_smiles_df = pd.read_csv(f\"/p/vast1/jones289/lit_pcba/{target}/actives.smi\", delim_whitespace=True, header=None)\n",
    "            inactive_smiles_df = pd.read_csv(f\"/p/vast1/jones289/lit_pcba/{target}/inactives.smi\", delim_whitespace=True, header=None)\n",
    "            target_smiles_df = pd.concat([active_smiles_df, inactive_smiles_df])\n",
    "\n",
    "\n",
    "\n",
    "            top_pose_target_df = target_df.groupby([' ligName'], as_index=False)[[' ligName', ' scores/1', 'y_true']].min()\n",
    "\n",
    "\n",
    "        \n",
    "            merged_df_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "            merged_df = pd.merge(top_pose_target_df, target_smiles_df, left_on=\" ligName\", right_on=1)\n",
    "            merged_df = merged_df[merged_df.apply(lambda x: x[0] in target_test_smiles_list, axis=1)]\n",
    "            merged_df['target'] = [target] * len(merged_df)\n",
    "            merged_df.to_csv(merged_df_path, index=False)\n",
    "        else:\n",
    "            merged_df = pd.read_csv(merged_df_path)\n",
    "            \n",
    "            if 'target' not in merged_df.columns:\n",
    "                merged_df['target'] = [target] * len(merged_df)\n",
    "                merged_df.to_csv(merged_df_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "        df_list.append(merged_df)\n",
    "\n",
    "    df = pd.concat(df_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_metric_df():\n",
    "    model_metric_dict = aggregate_results(dataset=\"lit-pcba\",multistep_p_list=[.05, .5],  \n",
    "                                          multistep_sklearn_model=\"rf\", \n",
    "                                         multistep_initial_p=.2)\n",
    "\n",
    "    model_metric_df = pd.DataFrame({key: value for key, value in model_metric_dict.items() if key not in [\"train_time\", \"test_time\", \"precision\", \"recall\", \"f1\"]})\n",
    "\n",
    "    # model_metric_df\n",
    "\n",
    "    #######\n",
    "    vina_result = docking_main(nrows=None)\n",
    "    vina_result\n",
    "    ###########\n",
    "\n",
    "    docking_dict = {\"enrich\": [], \"p\": [], \"model\": [], \"target\": []}\n",
    "\n",
    "    vina_enrich_list = []\n",
    "    target_list = []\n",
    "    vina_col=' scores/1'\n",
    "    for target, target_df in vina_result.groupby(\"target\"):\n",
    "\n",
    "        for p in [.1, .01]:\n",
    "            enrich = compute_enrichment_factor(sample_scores=np.abs(target_df[vina_col]), \n",
    "                                      sample_labels=target_df[\"y_true\"], \n",
    "                                      n_percent=p)\n",
    "\n",
    "            docking_dict[\"enrich\"].append(float(enrich))\n",
    "            docking_dict[\"p\"].append(p)\n",
    "            docking_dict[\"model\"].append(\"Vina\")\n",
    "            docking_dict[\"target\"].append(target)\n",
    "\n",
    "\n",
    "    ##################\n",
    "    model_metric_df = pd.concat([model_metric_df, pd.DataFrame(docking_dict)])\n",
    "    \n",
    "    # Backup the calculation\n",
    "    model_metric_df.to_csv(\"fixed_litpcba_model_metric_df.csv\")\n",
    "    \n",
    "    return model_metric_df    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_litpcba_model_metric_df.csv exists! reading it now...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "model_metric_df_path = Path(\"fixed_litpcba_model_metric_df.csv\")\n",
    "model_metric_df = None\n",
    "if model_metric_df_path.exists():\n",
    "    print(f\"{model_metric_df_path} exists! reading it now...\")\n",
    "    model_metric_df = pd.read_csv(model_metric_df_path, index_col=0)\n",
    "    print(\"done.\")\n",
    "    \n",
    "else:\n",
    "    print(f\"{model_metric_df_path} does not exist..computing it now..\")\n",
    "    model_metric_df = compute_model_metric_df()\n",
    "    print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     smiles-pe.atomwise.0\n",
       "1     smiles-pe.atomwise.0\n",
       "2     smiles-pe.atomwise.0\n",
       "3     smiles-pe.atomwise.0\n",
       "4     smiles-pe.atomwise.0\n",
       "              ...         \n",
       "25                    Vina\n",
       "26                    Vina\n",
       "27                    Vina\n",
       "28                    Vina\n",
       "29                    Vina\n",
       "Name: model, Length: 2160, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metric_df[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enrich_1_df.groupby(['model','target', 'p']).describe().to_csv(\"summary_ef_stats_1.csv\")\n",
    "(model_metric_df).groupby([\"model\", \"target\", \"p\"])[\"enrich\"].describe().to_csv(\"summary_ef_stats.csv\")\n",
    "# enrich_10_df.groupby(['model', 'target', 'p']).describe().to_csv(\"summary_ef_stats_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_box_plot(enrich_1_df, enrich_10_df):\n",
    "    \n",
    "    enrich_f, enrich_ax = plt.subplots(2,1, figsize=(12,10), sharex=True, sharey=False)\n",
    "    enrich_ax = enrich_ax.flatten()\n",
    "    enrich_1_ax, enrich_10_ax = enrich_ax[0], enrich_ax[1]\n",
    "    \n",
    "    sns.boxplot(data=enrich_1_df, x=\"model\", y=\"enrich\", ax=enrich_1_ax, palette=color_dict)\n",
    "    enrich_1_ax.set_title(\"(a) LIT-PCBA Enrichment at 1\\%\", fontdict={\"fontsize\": 18})\n",
    "    enrich_1_ax.set_xlabel(\"\")\n",
    "    enrich_1_ax.set_ylabel(\"\")\n",
    "    enrich_1_ax.tick_params(axis=\"x\", labelrotation=22.5)\n",
    "\n",
    "    enrich_1_ax.set_ylabel(\"EF\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    sns.boxplot(data=enrich_10_df, x=\"model\", y=\"enrich\", ax=enrich_10_ax, palette=color_dict)\n",
    "    enrich_10_ax.set_title(\"(b) LIT-PCBA Enrichment at 10\\%\", fontdict={\"fontsize\": 18})\n",
    "    enrich_10_ax.set_xlabel(\"\")\n",
    "    enrich_10_ax.set_ylabel(\"\")\n",
    "    enrich_10_ax.tick_params(axis=\"x\", labelrotation=22.5)\n",
    "    labels = [item.get_text() for item in enrich_10_ax.get_xticklabels()]\n",
    "    labels = [model_name_dict[x.get_text()] for x in enrich_10_ax.get_xticklabels()]\n",
    "#     labels[-1] = combo_model_name\n",
    "    enrich_10_ax.set_xticklabels(labels)\n",
    "    enrich_ax[0].set_ylabel(\"EF\")\n",
    "    enrich_ax[1].set_ylabel(\"EF\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # enrich_10_f.savefig(\"enrich_10.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    # enrich_10_f\n",
    "    \n",
    "    enrich_f.savefig(\"lit-pcba-enrich.png\", dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "#     return enrich_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the average over the random seeds dimension for each combo of MODEL X TARGET X P\n",
    "grp_df = (model_metric_df).groupby([\"model\", \"target\", \"p\"])[\"enrich\"].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target</th>\n",
       "      <th>p</th>\n",
       "      <th>enrich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDC-RF</td>\n",
       "      <td>ADRB2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HDC-RF</td>\n",
       "      <td>ALDH1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.584438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HDC-RF</td>\n",
       "      <td>ESR1_ago</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.997857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HDC-RF</td>\n",
       "      <td>ESR1_ant</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.084249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HDC-RF</td>\n",
       "      <td>FEN1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.467475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>smiles-pe.bpe.0</td>\n",
       "      <td>OPRK1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>smiles-pe.bpe.0</td>\n",
       "      <td>PKM2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.875884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>smiles-pe.bpe.0</td>\n",
       "      <td>PPARG</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>smiles-pe.bpe.0</td>\n",
       "      <td>TP53</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.977570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>smiles-pe.bpe.0</td>\n",
       "      <td>VDR</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.407231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               model    target    p    enrich\n",
       "1             HDC-RF     ADRB2  0.1  0.000000\n",
       "3             HDC-RF     ALDH1  0.1  1.584438\n",
       "5             HDC-RF  ESR1_ago  0.1  2.997857\n",
       "7             HDC-RF  ESR1_ant  0.1  3.084249\n",
       "9             HDC-RF      FEN1  0.1  2.467475\n",
       "..               ...       ...  ...       ...\n",
       "231  smiles-pe.bpe.0     OPRK1  0.1  3.333333\n",
       "233  smiles-pe.bpe.0      PKM2  0.1  0.875884\n",
       "235  smiles-pe.bpe.0     PPARG  0.1  0.000000\n",
       "237  smiles-pe.bpe.0      TP53  0.1  2.977570\n",
       "239  smiles-pe.bpe.0       VDR  0.1  0.407231\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_df[grp_df[\"p\"] == .1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>target</th>\n",
       "      <th>p</th>\n",
       "      <th>enrich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDC-RF</td>\n",
       "      <td>ADRB2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HDC-RF</td>\n",
       "      <td>ALDH1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8.043328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDC-RF</td>\n",
       "      <td>ESR1_ago</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.330952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HDC-RF</td>\n",
       "      <td>ESR1_ant</td>\n",
       "      <td>0.01</td>\n",
       "      <td>22.793787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HDC-RF</td>\n",
       "      <td>FEN1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>19.987191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>smiles-pe.bpe.0</td>\n",
       "      <td>OPRK1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>smiles-pe.bpe.0</td>\n",
       "      <td>PKM2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.457911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>smiles-pe.bpe.0</td>\n",
       "      <td>PPARG</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>smiles-pe.bpe.0</td>\n",
       "      <td>TP53</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.827273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>smiles-pe.bpe.0</td>\n",
       "      <td>VDR</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               model    target     p     enrich\n",
       "0             HDC-RF     ADRB2  0.01   0.000000\n",
       "2             HDC-RF     ALDH1  0.01   8.043328\n",
       "4             HDC-RF  ESR1_ago  0.01   3.330952\n",
       "6             HDC-RF  ESR1_ant  0.01  22.793787\n",
       "8             HDC-RF      FEN1  0.01  19.987191\n",
       "..               ...       ...   ...        ...\n",
       "230  smiles-pe.bpe.0     OPRK1  0.01   0.000000\n",
       "232  smiles-pe.bpe.0      PKM2  0.01   1.457911\n",
       "234  smiles-pe.bpe.0     PPARG  0.01   0.000000\n",
       "236  smiles-pe.bpe.0      TP53  0.01   4.827273\n",
       "238  smiles-pe.bpe.0       VDR  0.01   0.000000\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_df[grp_df[\"p\"] == .01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HDC-RF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmake_box_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43menrich_1_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrp_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrp_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.01\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43menrich_10_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrp_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrp_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mmake_box_plot\u001b[0;34m(enrich_1_df, enrich_10_df)\u001b[0m\n\u001b[1;32m      4\u001b[0m enrich_ax \u001b[38;5;241m=\u001b[39m enrich_ax\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      5\u001b[0m enrich_1_ax, enrich_10_ax \u001b[38;5;241m=\u001b[39m enrich_ax[\u001b[38;5;241m0\u001b[39m], enrich_ax[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menrich_1_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menrich\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menrich_1_ax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m enrich_1_ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(a) LIT-PCBA Enrichment at 1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontdict\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfontsize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m18\u001b[39m})\n\u001b[1;32m      9\u001b[0m enrich_1_ax\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/workspace/wsa/jones289/miniconda3/envs/HD_env/lib/python3.8/site-packages/seaborn/_decorators.py:46\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass the following variable\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mkeyword arg\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom version 0.12, the only valid positional argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/workspace/wsa/jones289/miniconda3/envs/HD_env/lib/python3.8/site-packages/seaborn/categorical.py:2243\u001b[0m, in \u001b[0;36mboxplot\u001b[0;34m(x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth, whis, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[1;32m   2232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mboxplot\u001b[39m(\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2240\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   2241\u001b[0m ):\n\u001b[0;32m-> 2243\u001b[0m     plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_BoxPlotter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m                          \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdodge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfliersize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2248\u001b[0m         ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "File \u001b[0;32m/usr/workspace/wsa/jones289/miniconda3/envs/HD_env/lib/python3.8/site-packages/seaborn/categorical.py:407\u001b[0m, in \u001b[0;36m_BoxPlotter.__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, orient, color, palette, saturation, width, dodge, fliersize, linewidth)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[1;32m    403\u001b[0m              orient, color, palette, saturation,\n\u001b[1;32m    404\u001b[0m              width, dodge, fliersize, linewidth):\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestablish_variables(x, y, hue, data, orient, order, hue_order)\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestablish_colors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdodge \u001b[38;5;241m=\u001b[39m dodge\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m width\n",
      "File \u001b[0;32m/usr/workspace/wsa/jones289/miniconda3/envs/HD_env/lib/python3.8/site-packages/seaborn/categorical.py:306\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_colors\u001b[0;34m(self, color, palette, saturation)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m             levels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhue_names\n\u001b[0;32m--> 306\u001b[0m         palette \u001b[38;5;241m=\u001b[39m [palette[l] \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m levels]\n\u001b[1;32m    308\u001b[0m     colors \u001b[38;5;241m=\u001b[39m color_palette(palette, n_colors)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Desaturate a bit because these are patches\u001b[39;00m\n",
      "File \u001b[0;32m/usr/workspace/wsa/jones289/miniconda3/envs/HD_env/lib/python3.8/site-packages/seaborn/categorical.py:306\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m             levels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhue_names\n\u001b[0;32m--> 306\u001b[0m         palette \u001b[38;5;241m=\u001b[39m [\u001b[43mpalette\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m levels]\n\u001b[1;32m    308\u001b[0m     colors \u001b[38;5;241m=\u001b[39m color_palette(palette, n_colors)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Desaturate a bit because these are patches\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'HDC-RF'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_box_plot(enrich_1_df=grp_df[grp_df[\"p\"] == .01], \n",
    "          enrich_10_df=grp_df[grp_df[\"p\"] == .1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_swarm_plot(enrich_1_df, enrich_10_df):\n",
    "\n",
    "    enrich_f, enrich_ax = plt.subplots(2,1, figsize=(12,10), sharex=True, sharey=False)\n",
    "    enrich_ax = enrich_ax.flatten()\n",
    "    enrich_1_ax, enrich_10_ax = enrich_ax[0], enrich_ax[1]\n",
    "    \n",
    "    sns.swarmplot(data=enrich_1_df, x=\"model\", y=\"enrich\", ax=enrich_1_ax, palette=color_dict)\n",
    "    enrich_1_ax.set_title(\"(a) LIT-PCBA Enrichment at 1\\%\", fontdict={\"fontsize\": 18})\n",
    "    enrich_1_ax.set_xlabel(\"\")\n",
    "    enrich_1_ax.set_ylabel(\"\")\n",
    "    enrich_1_ax.tick_params(axis=\"x\", labelrotation=22.5)\n",
    "\n",
    "    enrich_1_ax.set_ylabel(\"EF\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    sns.swarmplot(data=enrich_10_df, x=\"model\", y=\"enrich\", ax=enrich_10_ax, palette=color_dict)\n",
    "    enrich_10_ax.set_title(\"(b) LIT-PCBA Enrichment at 10\\%\", fontdict={\"fontsize\": 18})\n",
    "    enrich_10_ax.set_xlabel(\"\")\n",
    "    enrich_10_ax.set_ylabel(\"\")\n",
    "    enrich_10_ax.tick_params(axis=\"x\", labelrotation=22.5)\n",
    "    labels = [item.get_text() for item in enrich_10_ax.get_xticklabels()]\n",
    "    labels = [model_name_dict[x.get_text()] for x in enrich_10_ax.get_xticklabels()]\n",
    "#     labels[-1] = combo_model_name\n",
    "    enrich_10_ax.set_xticklabels(labels)\n",
    "    enrich_ax[0].set_ylabel(\"EF\")\n",
    "    enrich_ax[1].set_ylabel(\"EF\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # enrich_10_f.savefig(\"enrich_10.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    # enrich_10_f\n",
    "    \n",
    "    enrich_f.savefig(\"lit-pcba-enrich-swarm.png\", dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "#     return enrich_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_swarm_plot(enrich_1_df=grp_df[grp_df[\"p\"] == .01], \n",
    "          enrich_10_df=grp_df[grp_df[\"p\"] == .1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "def make_pc_plot(df):\n",
    "\n",
    "#     f, ax = plt.subplots(1,1, figsize=(12,10), sharex=True, sharey=False)\n",
    "\n",
    "    df_list = list(df.groupby([\"model\"]))\n",
    "    print(df_list)\n",
    "#     pc_df = pd.concat([group_df for group_name, group_df in df.groupby('model')], axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "#     ax = ax.flatten()\n",
    "#     enrich_1_ax, enrich_10_ax = enrich_ax[0], enrich_ax[1]\n",
    "    \n",
    "#     sns.swarmplot(data=model_1_df, x=\"model\", y=\"enrich\", ax=ax, palette=color_dict)\n",
    "#     enrich_1_ax.set_title(\"(a) LIT-PCBA Enrichment at 1\\%\", fontdict={\"fontsize\": 18})\n",
    "#     enrich_1_ax.set_xlabel(\"\")\n",
    "#     enrich_1_ax.set_ylabel(\"\")\n",
    "#     enrich_1_ax.tick_params(axis=\"x\", labelrotation=22.5)\n",
    "\n",
    "#     enrich_1_ax.set_ylabel(\"EF\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "\n",
    "    \n",
    "#     sns.swarmplot(data=enrich_10_df, x=\"model\", y=\"enrich\", ax=enrich_10_ax, palette=color_dict)\n",
    "#     enrich_10_ax.set_title(\"(b) LIT-PCBA Enrichment at 10\\%\", fontdict={\"fontsize\": 18})\n",
    "#     enrich_10_ax.set_xlabel(\"\")\n",
    "#     enrich_10_ax.set_ylabel(\"\")\n",
    "#     enrich_10_ax.tick_params(axis=\"x\", labelrotation=22.5)\n",
    "#     labels = [item.get_text() for item in enrich_10_ax.get_xticklabels()]\n",
    "#     labels = [model_name_dict[x.get_text()] for x in enrich_10_ax.get_xticklabels()]\n",
    "#     labels[-1] = combo_model_name\n",
    "#     enrich_10_ax.set_xticklabels(labels)\n",
    "#     enrich_ax[0].set_ylabel(\"EF\")\n",
    "#     enrich_ax[1].set_ylabel(\"EF\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "    # enrich_10_f.savefig(\"enrich_10.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    # enrich_10_f\n",
    "    \n",
    "#     enrich_f.savefig(\"lit-pcba-enrich-swarm.png\", dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "#     return enrich_f\n",
    "make_pc_plot(grp_df[grp_df[\"model\"].apply(lambda x: x in  [\"HDC-RF\", \"rf\", \"ecfp\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_time_results(dataset, range_limit=10):\n",
    "    \n",
    "\n",
    "    model_time_dict = {\"model\": [], \"target\": [], \"seed\": [],\"train_time\": [], \"test_time\": [], \"train_size\": [], \"test_size\": []}\n",
    "    \n",
    "    \n",
    "    tokenizer=\"atomwise\"\n",
    "    ngram_order=0\n",
    "    for model, color in tqdm(color_dict.items(), total=len(color_dict), position=0):\n",
    "                        \n",
    "        metric_list = []\n",
    "        test_time_list = []\n",
    "        train_size_list = []\n",
    "        test_size_list = []\n",
    "        target_size_list = []\n",
    "        eta_list = []\n",
    "\n",
    "        \n",
    "        if model not in [\"HDC-MLP\", \"HDC-RF\"]:\n",
    "            data_path_list = list(data_p.glob(f\"{dataset.replace('-','_')}*.{model}*pkl\"))\n",
    "\n",
    "        elif model in [\"HDC-MLP\", \"HDC-RF\"]:\n",
    "            data_path_list = list(data_p.glob(f\"{dataset.replace('-','_')}*.ecfp*pkl\"))\n",
    "    \n",
    "        for path in tqdm(data_path_list, total=len(data_path_list), position=1):\n",
    "\n",
    "            \n",
    "            with open(path, \"rb\") as handle:\n",
    "                model_data_dict = pickle.load(handle)\n",
    "\n",
    "            \n",
    "            target = path.name.split(\".\")[1]\n",
    "            \n",
    "            tqdm.write(f\"{target}, {path}, {model}\")\n",
    "\n",
    "            hd_cache_dir = f\"/p/lustre2/jones289/hd_cache/125/ecfp/{dataset}/random\"\n",
    "\n",
    "            for seed in range(range_limit):\n",
    "                    \n",
    "                model_time_dict[\"model\"].append(model)\n",
    "                model_time_dict[\"target\"].append(target)\n",
    "                model_time_dict[\"seed\"].append(seed)\n",
    "                model_time_dict[\"train_time\"].append(model_data_dict[seed][\"train_time\"])\n",
    "                model_time_dict[\"test_time\"].append(model_data_dict[seed][\"test_time\"])\n",
    "                model_time_dict[\"train_size\"].append(model_data_dict[seed][\"train_size\"])\n",
    "                model_time_dict[\"test_size\"].append(model_data_dict[seed][\"test_size\"])\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "    return model_time_dict\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = aggregate_time_results(dataset=\"lit-pcba\", range_limit=10)\n",
    "time_df = pd.DataFrame(time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df[\"test_latency\"] = time_df.apply(lambda x: x[\"test_time\"]/x[\"test_size\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## averaging over seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.groupby([\"model\", \"target\"])[\"test_latency\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## averaging over both seeds and target dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.groupby([\"model\", \"target\"])[\"test_latency\"].mean().reset_index().groupby(\"model\")[\"test_latency\"].median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"model\", y=\"test_latency\", data=time_df.groupby([\"model\", \"target\"])[\"test_latency\"].mean().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HD_env",
   "language": "python",
   "name": "hd_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
